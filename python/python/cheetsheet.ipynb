{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75e8b0a5",
   "metadata": {},
   "source": [
    "# Steps for starting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94317b9",
   "metadata": {},
   "source": [
    "1- Download environment from OneDrive\n",
    "\n",
    "2- Open Anaconda prompt and Anaconda Navigator\n",
    "\n",
    "3- copy and paste the environment to Downloads\n",
    "\n",
    "\n",
    "4- In Anaconda prompt write these commands:\n",
    "\n",
    " cd \"C:\\Users\\3120889D\"\n",
    "\n",
    " conda env create -f \"C:\\Users\\3120889D\\Downloads\\environment.yml\"\n",
    "\n",
    " conda activate condavenv\n",
    "\n",
    "\n",
    "5- Meanwhile open vs code and change the version of Jupyter to 5 months ago\n",
    "\n",
    "6- In Anaconda Navigator, change the environment to condavenv and launch VS Code\n",
    "\n",
    "7- Create a new folder on Downloads called exam\n",
    "\n",
    "8- Open the folder from VS Code\n",
    "\n",
    "9- Create a python script exam.py and make sure it is connected with the interpreter\n",
    "\n",
    "10- Create a Jupyter Notebook and run a cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1835149e",
   "metadata": {},
   "source": [
    "# General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede953a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlite3\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "df = pd.read_csv('sales_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653bee2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna({ # quick cleaning\n",
    "    'Product': 'Unknown',\n",
    "    'Quantity': 0,\n",
    "    'Price': 0.0,\n",
    "    'Total': 0.0\n",
    "}, inplace=True)\n",
    "\n",
    "monthly_sales = df.groupby('Month')['Total'].sum() # group by example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adde6d64",
   "metadata": {},
   "source": [
    "# Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152629f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# line plot\n",
    "plt.plot(x, y)\n",
    "plt.title(\"y = 2x\")\n",
    "plt.xlabel(\"x axis\")\n",
    "plt.ylabel(\"y axis\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5307cc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot from a dataframe\n",
    "df.plot(kind='bar') # bar plot\n",
    "df.plot(kind='line', title='Total Sales Over Time', ylabel='Total Sales', xlabel='Month') # line plot\n",
    "\n",
    "# or\n",
    "plt.plot(df.index, df.values) # note that df is a Series here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadea738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subplots\n",
    "x1 = [20, 30, 50, 60, 80]\n",
    "y1 = [10, 50, 100, 180, 200]\n",
    "x2 = [30, 40, 60, 70, 90]\n",
    "y2 = [20, 60, 110, 200, 220]\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.plot(x1, y1)\n",
    "plt.title(\"x1 and y1\")\n",
    "plt.subplot(222)\n",
    "plt.plot(x2, y2)\n",
    "plt.title(\"x2 and y2\")\n",
    "plt.subplot(223)\n",
    "plt.plot(x1, y1)\n",
    "plt.plot(x2, y2)\n",
    "plt.title(\"All together\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8873c65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bar plot\n",
    "proglang = [\"Python\", \"Java\", \"C\", \"C++\", \"R\", \"JavaScript\", \"C#\"]\n",
    "popularity = [100, 96.3, 94.4, 87.5, 81.5, 79.4, 74.5]\n",
    "\n",
    "plt.bar(proglang, popularity) # or plt.barh(proglang, popularity) for a horizental bar \n",
    "plt.title(\"Popularity of programming languages\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04157707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pie chart\n",
    "proglang = [\"Python\", \"Java\", \"C\", \"C++\", \"R\", \"JavaScript\", \"C#\"]\n",
    "popularity = [100, 96.3, 94.4, 87.5, 81.5, 79.4, 74.5]\n",
    "explode = [.6, 0, 0, 0, 0.4, 0.2, 0]\n",
    "colours = []\n",
    "for i in range(len(proglang)):\n",
    "    colours.append(np.random.random(3))\n",
    "plt.pie(popularity, labels=proglang, colors=colours, explode=explode, autopct=\"%1.1f%%\")\n",
    "plt.title(\"Popularity of programming languages\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57da215b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# error bar chart\n",
    "mean = [0.2474, 0.1235, 0.1737, 0.1824]\n",
    "stdev = [0.3314, 0.2278, 0.2836, 0.2645]\n",
    "\n",
    "plt.bar([\"Obs1\", \"Obs2\", \"Obs3\", \"Obs4\"], mean, yerr=stdev, error_kw={\"ecolor\": \"0.1\", \"capsize\": 4}, alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aaa9879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacked bar plot\n",
    "means_m = np.array([22, 30, 35, 35, 26])\n",
    "means_f = np.array([25, 32, 30, 35, 29])\n",
    "stdev_m = np.array([4, 3, 4, 1, 5])\n",
    "stdev_f = np.array([3, 5, 2, 3, 3])\n",
    "columns = (\"Obs1\", \"Obs2\", \"Obs3\", \"Obs4\", \"Obs5\")\n",
    "\n",
    "plt.bar(columns, means_m, facecolor=\"blue\", yerr=stdev_m, error_kw={\"capsize\": 4}, alpha=0.7)\n",
    "plt.bar(columns, means_f, facecolor=\"red\", yerr=stdev_f, error_kw={\"capsize\": 4}, alpha=0.7, bottom=means_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45284289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot\n",
    "x = np.random.random(100)\n",
    "y = np.random.random(100)\n",
    "sizes = np.random.randint(50,500,100)\n",
    "colors = np.random.random(100)\n",
    "\n",
    "plt.scatter(x, y, sizes, c=colors, alpha=0.5)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# another scatter\n",
    "java_marks = [88, 92, 80, 89, 100, 80, 60, 100, 80, 34]\n",
    "python_marks = [35, 79, 79, 48, 100, 88, 32, 45, 20, 30]\n",
    "marks_range = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "\n",
    "plt.scatter(java_marks, python_marks)\n",
    "plt.xlim(marks_range[0], marks_range[-1]+10)\n",
    "plt.ylim(marks_range[0], marks_range[-1]+10)\n",
    "plt.xlabel(\"Java Marks\")\n",
    "plt.ylabel(\"Python Marks\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708bf9fa",
   "metadata": {},
   "source": [
    "# SQLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4d09ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "with sqlite3.connect('SalesDB') as db:\n",
    "    cursor = db.cursor()\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS SALES (\n",
    "    Date DATETIME PRIMARY KEY, \n",
    "    Product TEXT, \n",
    "    Quantity INTEGER, \n",
    "    Price REAL, \n",
    "    Total REAL\n",
    "    );\"\"\")\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    try:\n",
    "        cursor.execute(\"\"\"INSERT INTO Sales (\n",
    "            Date, Product, Quantity, Price, Total) \n",
    "            VALUES(?,?,?,?,?)\"\"\",\n",
    "            (row['Date'].strftime('%Y-%m-%d %H:%M:%S'), row['Product'], row['Quantity'], row['Price'], row['Total'])\n",
    "        )\n",
    "        db.commit()\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723d5354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cursor.execute(\"SELECT * FROM SALES\")\n",
    "# for x in cursor.fetchall():\n",
    "#     print(x)\n",
    "\n",
    "#OR\n",
    "\n",
    "query = \"SELECT * FROM SALES\"\n",
    "df = pd.read_sql_query(query, db)\n",
    "print(\"Data Loaded and Cleaned:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e5c3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('''\n",
    "    SELECT SUM(Total) FROM Sales WHERE strftime('%Y', Date) = '2023'\n",
    "''')\n",
    "total_sales = cursor.fetchone()[0]\n",
    "print(f\"Total Sales in 2023: {total_sales}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3bf4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"SELECT product, sum(quantity) FROM SALES WHERE strftime('%Y', Date) = '2023' group by product order by sum(quantity) desc\"\"\")\n",
    "for x in cursor.fetchall():\n",
    "    print(x)\n",
    "\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3012c00",
   "metadata": {},
   "source": [
    "# PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7abbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 5)  # Input layer: 10 features -> 5 neurons\n",
    "        self.fc2 = nn.Linear(5, 3)   # Hidden layer: 5 neurons -> 3 neurons\n",
    "        self.fc3 = nn.Linear(3, 1)   # Output layer: 3 neurons -> 1 neuron\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model = SimpleNN()\n",
    "criterion = nn.MSELoss()  # Mean Squared Error loss function\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)  # OR x = torch.softmax(self.fc3(x), dim=1)\n",
    "\n",
    "# Generate synthetic data\n",
    "data = torch.randn(100, 10)  # 100 samples, 10 features each\n",
    "target = torch.randn(100, 1)  # 100 target values\n",
    "\n",
    "# Training the network\n",
    "losses = []\n",
    "for epoch in range(20):  # Train for 20 epochs\n",
    "    optimizer.zero_grad()  # Zero the gradients\n",
    "    output = model(data)  # Forward pass\n",
    "    loss = criterion(output, target)  # Compute the loss\n",
    "    loss.backward()  # Backpropagation\n",
    "    optimizer.step()  # Update weights\n",
    "    losses.append(loss.item())  # Record the loss\n",
    "\n",
    "# Plotting the training loss over time\n",
    "plt.plot(losses)\n",
    "plt.title('Training Loss Over Time')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd81123",
   "metadata": {},
   "source": [
    "# Past Exam Official Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4b36f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Aug 26 16:04:27 2024\n",
    "\n",
    "@author: mireilla\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlite3\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# --- Part 1: Python Basics and Data Manipulation ---\n",
    "\n",
    "# Task 1a: Data Loading and Preprocessing\n",
    "# Load the data and parse dates\n",
    "df = pd.read_csv('sales_data.csv', parse_dates=['Date'], dayfirst=True)\n",
    "\n",
    "# Data Cleaning\n",
    "# Fill missing values\n",
    "df.fillna({\n",
    "    'Product': 'Unknown',\n",
    "    'Quantity': 0,\n",
    "    'Price': 0.0,\n",
    "    'Total': 0.0\n",
    "}, inplace=True)\n",
    "\n",
    "# Keep the original datetime column for operations\n",
    "df['Date_original'] = df['Date']\n",
    "\n",
    "# Convert Date to Period (Month) using the original datetime column\n",
    "df['Month'] = df['Date_original'].dt.to_period('M')\n",
    "\n",
    "# Ensure Total column is correct\n",
    "df['Total'] = df['Quantity'] * df['Price']\n",
    "\n",
    "print(\"Data Loaded and Cleaned:\")\n",
    "print(df.head())\n",
    "\n",
    "# Task 1b: Data Visualization\n",
    "# Product Sales Distribution\n",
    "product_sales = df.groupby('Product')['Quantity'].sum()\n",
    "product_sales.plot(kind='bar', title='Product Sales Distribution', ylabel='Total Quantity Sold', xlabel='Product')\n",
    "plt.show()\n",
    "\n",
    "# Sales Over Time (2023)\n",
    "# Group by Month and calculate total sales per month\n",
    "monthly_sales = df.groupby('Month')['Total'].sum()\n",
    "\n",
    "# Plot the results\n",
    "monthly_sales.plot(kind='line', title='Total Sales Over Time', ylabel='Total Sales', xlabel='Month')\n",
    "plt.show()\n",
    "\n",
    "# Convert Date to string for database insertion\n",
    "df['Date'] = df['Date_original'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# --- Part 2: Python Database Management ---\n",
    "\n",
    "# Task 2a: Database Creation and Data Insertion\n",
    "# Create the database\n",
    "conn = sqlite3.connect('SalesDB.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create the Sales table\n",
    "cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS Sales (\n",
    "        Date TEXT,\n",
    "        Product TEXT,\n",
    "        Quantity INTEGER,\n",
    "        Price REAL,\n",
    "        Total REAL\n",
    "    )\n",
    "''')\n",
    "\n",
    "# Insert data into the Sales table\n",
    "for _, row in df.iterrows():\n",
    "    cursor.execute('''\n",
    "        INSERT OR IGNORE INTO Sales (Date, Product, Quantity, Price, Total)\n",
    "        VALUES (?, ?, ?, ?, ?)\n",
    "    ''', (row['Date'], row['Product'], row['Quantity'], row['Price'], row['Total']))\n",
    "\n",
    "conn.commit()\n",
    "print(\"Data inserted into SalesDB.\")\n",
    "\n",
    "# Task 2b: Querying the Database\n",
    "# Total Sales Calculation\n",
    "cursor.execute('''\n",
    "    SELECT SUM(Total) FROM Sales WHERE strftime('%Y', Date) = '2023'\n",
    "''')\n",
    "total_sales = cursor.fetchone()[0]\n",
    "print(f\"Total Sales in 2023: {total_sales}\")\n",
    "\n",
    "# Product Sales Summary\n",
    "cursor.execute('''\n",
    "    SELECT Product, SUM(Quantity) FROM Sales \n",
    "    WHERE strftime('%Y', Date) = '2023' \n",
    "    GROUP BY Product \n",
    "    ORDER BY SUM(Quantity) DESC\n",
    "''')\n",
    "product_summary = cursor.fetchall()\n",
    "print(\"Product Sales Summary in 2023:\")\n",
    "for product, total_quantity in product_summary:\n",
    "    print(f\"Product: {product}, Total Quantity Sold: {total_quantity}\")\n",
    "\n",
    "conn.close()\n",
    "\n",
    "# --- Part 3: Basic Neural Network Implementation ---\n",
    "\n",
    "# Task 3a: Neural Network Construction\n",
    "# Define the neural network\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 5)  # Input layer: 10 features -> 5 neurons\n",
    "        self.fc2 = nn.Linear(5, 3)   # Hidden layer: 5 neurons -> 3 neurons\n",
    "        self.fc3 = nn.Linear(3, 1)   # Output layer: 3 neurons -> 1 neuron\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model = SimpleNN()\n",
    "criterion = nn.MSELoss()  # Mean Squared Error loss function\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)  # Stochastic Gradient Descent optimizer\n",
    "\n",
    "# Generate synthetic data\n",
    "data = torch.randn(100, 10)  # 100 samples, 10 features each\n",
    "target = torch.randn(100, 1)  # 100 target values\n",
    "\n",
    "# Training the network\n",
    "losses = []\n",
    "for epoch in range(20):  # Train for 20 epochs\n",
    "    optimizer.zero_grad()  # Zero the gradients\n",
    "    output = model(data)  # Forward pass\n",
    "    loss = criterion(output, target)  # Compute the loss\n",
    "    loss.backward()  # Backpropagation\n",
    "    optimizer.step()  # Update weights\n",
    "    losses.append(loss.item())  # Record the loss\n",
    "\n",
    "# Plotting the training loss over time\n",
    "plt.plot(losses)\n",
    "plt.title('Training Loss Over Time')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2f5793",
   "metadata": {},
   "source": [
    "# Files and Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66f1d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"(1) Create a new file\")\n",
    "print(\"(2) Display the file\")\n",
    "print(\"(3) Add a new item to the file\")\n",
    "selection = int(input(\"Make a selection 1, 2 or 3: \"))\n",
    "if selection == 1:\n",
    "    subject = input(\"Enter a school subject: \")\n",
    "    file = open(\"Subject.txt\", \"w\")\n",
    "    file.write(subject + \"\\n\")\n",
    "    file.close()\n",
    "elif selection == 2:\n",
    "    file = open(\"Subject.txt\", \"r\")\n",
    "    print(file.read())\n",
    "    file.close()\n",
    "elif selection == 3:\n",
    "    file = open(\"Subject.txt\", \"a\")\n",
    "    subject = input(\"Enter a school subject: \")\n",
    "    file.write(subject + \"\\n\")\n",
    "    file.close()\n",
    "    file = open(\"Subject.txt\", \"r\")\n",
    "    print(file.read())\n",
    "    file.close()\n",
    "else:\n",
    "    print(\"Invalid option\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe531eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random\n",
    "import random\n",
    "print(random.randint(1,10))        # random integer between 1 and 10\n",
    "print(random.random())             # random float 0.0–1.0\n",
    "print(random.uniform(5,15))        # random float between 5 and 15\n",
    "print(random.choice([1,2,3,4]))    # random element from list\n",
    "nums = [1,2,3,4,5]\n",
    "random.shuffle(nums)               # shuffle list in place\n",
    "print(nums)\n",
    "print(random.sample(range(100),5)) # pick 5 unique random numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88418e9e",
   "metadata": {},
   "source": [
    "# Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0648f4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create arrays + dtype\n",
    "a=np.array([1,2,3])\n",
    "b=np.array([(1,2,3),(4,5,6)],dtype=float)\n",
    "c=np.array([[1,2],[3,4]],dtype=np.int32)\n",
    "\n",
    "# Constructors\n",
    "z=np.zeros((2,3))\n",
    "o=np.ones((2,3))\n",
    "eye=np.eye(3)\n",
    "diag=np.diag([1,2,3])\n",
    "r=np.arange(0,10,2)\n",
    "l=np.linspace(0,1,5)\n",
    "u=np.random.random((2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb34400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arithmetic (elementwise)\n",
    "x=np.array([1,2,3]);y=np.array([4,5,6])\n",
    "s=x+y\n",
    "p=x*y\n",
    "q=x**2\n",
    "m=x+10\n",
    "\n",
    "# Matrix product\n",
    "A=np.array([[0,1,2],[3,4,5]])\n",
    "B=np.array([[1],[1],[1]])\n",
    "M=A.dot(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d360ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorized funcs\n",
    "y=np.sin(x)\n",
    "rt=np.sqrt(x)\n",
    "cond=(x>1)\n",
    "all_ok=np.all(cond)\n",
    "any_ok=np.any(cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7e590b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose, trace, inverse\n",
    "C=np.array([[1.,2.],[3.,4.]])\n",
    "Ct=C.T\n",
    "tr=np.trace(C)\n",
    "inv=np.linalg.inv(C)\n",
    "\n",
    "# Shape ops\n",
    "d=np.arange(12)\n",
    "e=d.reshape(3,4)\n",
    "f=e.ravel()\n",
    "e.shape=(4,3)  # in-place reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e36412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack + split\n",
    "g=np.array([[1,2],[3,4]])\n",
    "h=np.array([[5,6],[7,8]])\n",
    "vs=np.vstack((g,h))\n",
    "hs=np.hstack((g,h))\n",
    "cs=np.column_stack((g,h))\n",
    "rs=np.row_stack((g,h))\n",
    "hs1,hs2=np.hsplit(vs,2)\n",
    "vs1,vs2=np.vsplit(vs,2)\n",
    "sp=np.split(np.arange(10),[1,3,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b29eb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save/Load text\n",
    "X=np.arange(6).reshape(3,2)\n",
    "np.savetxt(\"data.txt\",X,fmt=\"%.3f\",delimiter=\",\")\n",
    "Y=np.loadtxt(\"data.txt\",delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce73aacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random samples useful for plotting\n",
    "rng=np.random.default_rng(0)\n",
    "x=rng.normal(0,1,100)\n",
    "y=rng.normal(0,1,100)\n",
    "sizes=rng.integers(10,200,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f08519",
   "metadata": {},
   "source": [
    "# Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3f07ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df=pd.read_csv(\"data.csv\")                   # basic load\n",
    "df=pd.read_csv(\"data.csv\",parse_dates=[\"date\"],dayfirst=False)  # parse dates\n",
    "\n",
    "# Inspect\n",
    "df.head(3)                                   # first rows\n",
    "df.info()                                    # dtypes and nulls\n",
    "df.describe(numeric_only=True)               # summary stats\n",
    "\n",
    "# Types and categories\n",
    "df[\"id\"]=df[\"id\"].astype(\"int64\")\n",
    "df[\"cat\"]=df[\"cat\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a51974c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns/rows\n",
    "df[\"col\"]; df[[\"a\",\"b\"]]                     # cols\n",
    "df.loc[df[\"a\"]>0,[\"a\",\"b\"]]                  # label filter + subset\n",
    "df.iloc[0:5,0:2]                             # position-based\n",
    "\n",
    "# Filter and assign\n",
    "df=df[df[\"score\"].ge(50)]                    # keep rows\n",
    "df[\"ratio\"]=df[\"x\"]/df[\"y\"]                  # new col\n",
    "df=df.assign(z=lambda d:d.x+d.y)             # assign with lambda\n",
    "\n",
    "# Missing values\n",
    "df.isna().sum()                              # null counts\n",
    "df=df.dropna(subset=[\"a\",\"b\"])               # drop if a or b is NaN\n",
    "df[\"a\"]=df[\"a\"].fillna(0)                    # fill\n",
    "\n",
    "# Duplicates\n",
    "df=df.drop_duplicates(subset=[\"id\",\"date\"],keep=\"last\")\n",
    "\n",
    "# Value counts and uniques\n",
    "df[\"city\"].value_counts(normalize=True)      # proportions\n",
    "df[\"city\"].nunique()\n",
    "\n",
    "# Sorting and ranking\n",
    "df=df.sort_values([\"score\",\"date\"],ascending=[False,True])\n",
    "df[\"rk\"]=df[\"score\"].rank(method=\"dense\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eceda2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping and aggregation\n",
    "grp=df.groupby(\"category\")[\"value\"].agg([\"count\",\"mean\",\"sum\"])\n",
    "out=df.groupby(\"city\").agg({\n",
    "    \"sales\":\"sum\",       # total sales per city\n",
    "    \"orders\":\"mean\",     # avg orders per city\n",
    "    \"date\":\"max\"         # latest date per city\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9166db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dates and strings\n",
    "df[\"date\"]=pd.to_datetime(df[\"date\"])\n",
    "df[\"year\"]=df[\"date\"].dt.year\n",
    "df[\"name\"]=df[\"name\"].str.strip().str.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4ac7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge / join\n",
    "left.merge(right,how=\"left\",on=\"key\")        # keys must exist in both\n",
    "pd.concat([df1,df2],axis=0,ignore_index=True) # append rows and axis=1 for columns\n",
    "# Pivot\n",
    "pd.pivot_table(df,index=\"city\",columns=\"month\",values=\"sales\",aggfunc=\"sum\",fill_value=0)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
